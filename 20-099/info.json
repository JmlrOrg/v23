{
    "abstract": "Encoding the scale information explicitly into the representation learned by a convolutional neural network (CNN) is beneficial for many computer vision tasks especially when dealing with multiscale inputs. We study, in this paper, a scaling-translation-equivariant ($\\mathcal{ST}$-equivariant) CNN with joint convolutions across the space and  the scaling group, which is shown to be both sufficient and necessary to achieve equivariance for the regular representation of the scaling-translation group $\\mathcal{ST}$. To reduce the model complexity and computational burden,  we decompose the convolutional filters under two pre-fixed separable bases and truncate the expansion to  low-frequency components. A further benefit of the truncated filter expansion is the improved deformation robustness of the equivariant representation, a property which is theoretically analyzed and empirically verified. Numerical experiments demonstrate that the proposed scaling-translation-equivariant network with decomposed convolutional filters (ScDCFNet) achieves significantly improved performance in multiscale image classification and better interpretability than regular CNNs at a reduced model size.",
    "authors": [
        "Wei Zhu",
        "Qiang Qiu",
        "Robert Calderbank",
        "Guillermo Sapiro",
        "Xiuyuan Cheng"
    ],
    "emails": [
        "zhu@math.umass.edu",
        "qiang.qiu@duke.edu",
        "robert.calderbank@duke.edu",
        "guillermo.sapiro@duke.edu",
        "xiuyuan.cheng@duke.edu"
    ],
    "id": "20-099",
    "issue": 68,
    "pages": [
        1,
        45
    ],
    "title": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional Filters",
    "volume": 23,
    "year": 2022
}