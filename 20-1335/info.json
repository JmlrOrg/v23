{
    "abstract": "Machine learning (ML) systems often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification in ML pipelines as a key reason for these failures. An ML pipeline is the full procedure followed to train and validate a predictor. Such a pipeline is underspecified when it can return many distinct predictors with equivalently strong test performance. Underspecification is common in modern ML pipelines that primarily validate predictors on held-out data that follow the same distribution as the training data. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We provide evidence that underspecfication has substantive implications for practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.",
    "authors": [
        "Alexander D'Amour",
        "Katherine Heller",
        "Dan Moldovan",
        "Ben Adlam",
        "Babak Alipanahi",
        "Alex Beutel",
        "Christina Chen",
        "Jonathan Deaton",
        "Jacob Eisenstein",
        "Matthew D. Hoffman",
        "Farhad Hormozdiari",
        "Neil Houlsby",
        "Shaobo Hou",
        "Ghassen Jerfel",
        "Alan Karthikesalingam",
        "Mario Lucic",
        "Yian Ma",
        "Cory McLean",
        "Diana Mincu",
        "Akinori Mitani",
        "Andrea Montanari",
        "Zachary Nado",
        "Vivek Natarajan",
        "Christopher Nielson",
        "Thomas F. Osborne",
        "Rajiv Raman",
        "Kim Ramasamy",
        "Rory Sayres",
        "Jessica Schrouff",
        "Martin Seneviratne",
        "Shannon Sequeira",
        "Harini Suresh",
        "Victor Veitch",
        "Max Vladymyrov",
        "Xuezhi Wang",
        "Kellie Webster",
        "Steve Yadlowsky",
        "Taedong Yun",
        "Xiaohua Zhai",
        "D. Sculley"
    ],
    "emails": [
        "alexdamour@google.com",
        "kheller@google.com",
        "mdan@google.com",
        "adlam@google.com",
        "babaka@google.com",
        "alexbeutel@google.com",
        "christinium@google.com",
        "jdeaton@google.com",
        "jeisenstein@google.com",
        "mhoffman@google.com",
        "fhormoz@google.com",
        "neilhoulsby@google.com",
        "shaobohou@google.com",
        "ghassen@google.com",
        "alankarthi@google.com",
        "lucic@google.com",
        "yianma@ucsd.edu",
        "cym@google.com",
        "dmincu@google.com",
        "amitani@google.com",
        "montanari@stanford.edu",
        "znado@google.com",
        "natviv@google.com",
        "christopher.nielson@va.gov",
        "thomas.osborne@va.gov",
        "drrrn@snmail.org",
        "kim@aravind.org",
        "sayres@google.com",
        "schrouff@google.com",
        "martsen@google.com",
        "shnnn@google.com",
        "hsuresh@mit.edu",
        "victorveitch@google.com",
        "mxv@google.com",
        "xuezhiw@google.com",
        "websterk@google.com",
        "yadlowsky@google.com",
        "tedyun@google.com",
        "xzhai@google.com",
        "dsculley@google.com"
    ],
    "id": "20-1335",
    "issue": 226,
    "pages": [
        1,
        61
    ],
    "title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning",
    "volume": 23,
    "year": 2022
}